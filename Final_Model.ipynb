{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP0zmtgFDezabgx08qHlV10",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Haarya/Twitter-Sentiment-Analysis/blob/main/Final_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9r3eDlrj4pGr",
        "outputId": "1993fe2a-ce85-4f86-8894-8d3ad5f4b2cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "\n",
        "# --- Setup: NLTK and Stemmer ---\n",
        "# This ensures the 'stopwords' dataset is available\n",
        "try:\n",
        "    stopwords.words('english')\n",
        "except LookupError:\n",
        "    nltk.download('stopwords')\n",
        "\n",
        "port_stem = PorterStemmer()\n",
        "\n",
        "# --- 1. Load the Saved Model and Vectorizer ---\n",
        "try:\n",
        "    vectorizer = pickle.load(open('vectorizer.sav', 'rb'))\n",
        "    loaded_model = pickle.load(open('trained_model.sav', 'rb'))\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: 'vectorizer.sav' or 'trained_model.sav' not found.\")\n",
        "    print(\"Please run the 'train.py' script first to generate these files.\")\n",
        "    exit()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 2. Preprocessing function (must be identical to the one in train.py) ---\n",
        "def preprocess_tweet(content):\n",
        "    \"\"\"\n",
        "    Cleans and prepares a single tweet string for the model.\n",
        "    \"\"\"\n",
        "    # Remove non-alphabetic characters, convert to lowercase, and split\n",
        "    stemmed_content = re.sub('[^a-zA-Z]', ' ', content)\n",
        "    stemmed_content = stemmed_content.lower().split()\n",
        "\n",
        "    # Remove stopwords and apply stemming\n",
        "    stemmed_content = [port_stem.stem(word) for word in stemmed_content if not word in stopwords.words('english')]\n",
        "\n",
        "    # Rejoin the words into a single string\n",
        "    stemmed_content = ' '.join(stemmed_content)\n",
        "    return stemmed_content\n",
        "\n",
        "# --- 3. Prediction function ---\n",
        "def predict_sentiment(tweet_text):\n",
        "    \"\"\"\n",
        "    Takes raw text, preprocesses it, and returns the predicted sentiment.\n",
        "    \"\"\"\n",
        "    # Handle empty or whitespace-only input\n",
        "    if not tweet_text.strip():\n",
        "        return \"Cannot analyze empty text.\"\n",
        "\n",
        "    processed_tweet = preprocess_tweet(tweet_text)\n",
        "    tweet_vector = vectorizer.transform([processed_tweet])\n",
        "    prediction = loaded_model.predict(tweet_vector)\n",
        "\n",
        "    return 'Positive' if prediction[0] == 1 else 'Negative'\n",
        "\n"
      ],
      "metadata": {
        "id": "aUa8nw9x403k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Main loop for user interaction ---\n",
        "if __name__ == '__main__':\n",
        "    print(\"\\n--- Twitter Sentiment Analyzer ---\")\n",
        "    print(\"Enter a sentence to analyze, or type 'quit' to exit.\")\n",
        "    print(\"----------------------------------\")\n",
        "\n",
        "    while True:\n",
        "        # Get input from the user\n",
        "        user_input = input(\"\\nEnter your text: \")\n",
        "\n",
        "        # Check if the user wants to exit\n",
        "        if user_input.lower() == 'quit':\n",
        "            print(\"Exiting program. Goodbye!\")\n",
        "            break\n",
        "\n",
        "        # Get the prediction and print it\n",
        "        sentiment = predict_sentiment(user_input)\n",
        "        print(f\"--> Predicted Sentiment: {sentiment}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q3G2CVcZ4zMj",
        "outputId": "c8099897-229f-459e-d137-553c9d7a2e54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Twitter Sentiment Analyzer ---\n",
            "Enter a sentence to analyze, or type 'quit' to exit.\n",
            "----------------------------------\n",
            "\n",
            "Enter your text: I'm so excited for the concert tonight, it's going to be an amazing show!\n",
            "--> Predicted Sentiment: Positive\n",
            "\n",
            "Enter your text: Waited an hour for my food and it arrived cold. I'm so disappointed with the service.\n",
            "--> Predicted Sentiment: Negative\n",
            "\n",
            "Enter your text: quit\n",
            "Exiting program. Goodbye!\n"
          ]
        }
      ]
    }
  ]
}